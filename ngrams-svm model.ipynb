{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "import scipy.stats as stats\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2400 entries, 0 to 2399\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2400 non-null   object\n",
      " 1   Polarity  2400 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 37.6+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0                           Wow... Loved this place.         1\n",
      "1                                 Crust is not good.         0\n",
      "2          Not tasty and the texture was just nasty.         0\n",
      "3  Stopped by during the late May bank holiday of...         1\n",
      "4  The selection on the menu was great and so wer...         1\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"sentiment_train (1).csv\")\n",
    "\n",
    "print(df_train.info())\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  600 non-null    object\n",
      " 1   Polarity  600 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.5+ KB\n",
      "None\n",
      "                                            Sentence  Polarity\n",
      "0  A good commentary of today's love and undoubte...         1\n",
      "1  For people who are first timers in film making...         1\n",
      "2  It was very popular when I was in the cinema, ...         1\n",
      "3  It's a feel-good film and that's how I felt wh...         1\n",
      "4  It has northern humour and positive about the ...         1\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"sentiment_test.csv\")\n",
    "\n",
    "print(df_test.info())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weren', 'shouldn', 'yours', 'her', 'which', 'how', 'very', 'been', 'shan', 's', 'between', 'where', 'o', \"weren't\", 'up', 'are', 'being', 'about', 'a', 'haven', 'to', \"isn't\", 'he', 'did', 'its', 'my', 'we', 'm', 'hasn', 'before', 'you', 'yourselves', 'hadn', 'their', 'wasn', \"mustn't\", 'theirs', 'this', 'didn', 'above', 'as', 'do', 'aren', \"mightn't\", \"won't\", 'itself', \"it's\", 'once', 'the', 'all', 'over', 'me', 'with', 'll', 'having', 'further', 'than', 'while', 'in', 'then', 'more', 'other', 'only', 't', 'both', \"that'll\", 'y', 'ourselves', \"you're\", 'few', 'don', 'who', 'most', 'mightn', \"needn't\", 'our', 'if', \"haven't\", 'an', 'whom', 'needn', 're', 'himself', 'or', 'that', 'now', 'ain', 'them', 'from', 'some', 'does', 'themselves', 'why', 'during', 'down', 'into', \"don't\", 'out', 'isn', \"you've\", 'after', 'at', \"doesn't\", 'yourself', 'same', 'again', \"she's\", 'mustn', \"shouldn't\", \"you'd\", 'against', 'these', 'wouldn', 'and', 'off', 'is', 'ours', 'what', 'can', 'ma', 'was', 'by', 'own', 'his', 'until', 'here', 'herself', 'be', 'your', 'couldn', 'nor', 'of', 'when', 'under', 'there', 'such', 'it', 'has', \"should've\", 'i', 'each', \"hasn't\", 'him', 'they', 'through', 'will', 'won', 'hers', \"hadn't\", 'just', 'were', 'had', 'too', 'should', 'but', \"shan't\", 'have', 'because', 'those', \"you'll\", 'am', 'so', 'she', 'any', \"wasn't\", 'd', 'doesn', 'doing', 've', 'for', 'myself', \"didn't\", 'on'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english')) -{'not', 'no', \"wouldn't\", \"couldn't\", \"aren't\", \"below\"}\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    # Lower case\n",
    "    x = x.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    x = BeautifulSoup(x, \"lxml\").get_text()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "\n",
    "    # Remove numbers\n",
    "    x = re.sub(r'\\d+', '', x)\n",
    "    \n",
    "     # Remove URLs\n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    " \n",
    "    # Remove single characters from the start\n",
    "    x = re.sub(r'\\^[a-zA-Z]\\s+', ' ', x) \n",
    "    \n",
    "    \n",
    "     # Substituting multiple spaces with single space\n",
    "    x = re.sub(r'\\s+', ' ',x, flags=re.I)\n",
    "\n",
    "    # Remove stopwords and lemmatize\n",
    "    x = [lemmer.lemmatize(w) for w in x.split() if w not in stop_words]\n",
    "    return ' '.join(x) \n",
    " \n",
    "\n",
    "df_train['Sentence_pre'] = df_train['Sentence'].apply(preprocess)\n",
    "\n",
    "df_test['Sentence_pre'] = df_test['Sentence'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence  Polarity  \\\n",
      "0                           Wow... Loved this place.         1   \n",
      "1                                 Crust is not good.         0   \n",
      "2          Not tasty and the texture was just nasty.         0   \n",
      "3  Stopped by during the late May bank holiday of...         1   \n",
      "4  The selection on the menu was great and so wer...         1   \n",
      "\n",
      "                                        Sentence_pre  \n",
      "0                                    wow loved place  \n",
      "1                                     crust not good  \n",
      "2                            not tasty texture nasty  \n",
      "3  stopped late may bank holiday rick steve recom...  \n",
      "4                         selection menu great price  \n",
      "                                            Sentence  Polarity  \\\n",
      "0  A good commentary of today's love and undoubte...         1   \n",
      "1  For people who are first timers in film making...         1   \n",
      "2  It was very popular when I was in the cinema, ...         1   \n",
      "3  It's a feel-good film and that's how I felt wh...         1   \n",
      "4  It has northern humour and positive about the ...         1   \n",
      "\n",
      "                                        Sentence_pre  \n",
      "0  good commentary today love undoubtedly film wo...  \n",
      "1  people first timer film making think excellent...  \n",
      "2  popular cinema good house good reaction plenty...  \n",
      "3               feelgood film thats felt came cinema  \n",
      "4      northern humour positive community represents  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())\n",
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 3), preprocessor=None,\n",
       "                stop_words={'a', 'about', 'above', 'after', 'again', 'against',\n",
       "                            'ain', 'all', 'am', 'an', 'and', 'any', 'are',\n",
       "                            'aren', 'as', 'at', 'be', 'because', 'been',\n",
       "                            'before', 'being', 'between', 'both', 'but', 'by',\n",
       "                            'can', 'couldn', 'd', 'did', 'didn', ...},\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    \n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words= stop_words)\n",
    "\n",
    "ngram_vectorizer.fit(df_train[\"Sentence_pre\"])\n",
    "\n",
    "X = ngram_vectorizer.transform(df_train[\"Sentence_pre\"])\n",
    "\n",
    "X_test = ngram_vectorizer.transform(df_test[\"Sentence_pre\"])\n",
    "y = df_train['Polarity']\n",
    "y_test=df_test['Polarity']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, train_size = 0.75)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.05: 0.8266666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.25, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.25: 0.8233333333333334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.5, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.5: 0.8216666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=1: 0.8183333333333334\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01]:\n",
    "    svm1 = LinearSVC(C=c)\n",
    "svm1.fit(X_train, y_train)\n",
    "\n",
    "print (\"Accuracy for C=%s: %s\"\n",
    "       % (c, accuracy_score(y_val, svm1.predict(X_val))))\n",
    "\n",
    "for c in [0.05]:\n",
    "    svm2 = LinearSVC(C=c)\n",
    "svm2.fit(X_train, y_train)\n",
    "\n",
    "print (\"Accuracy for C=%s: %s\"\n",
    "       % (c, accuracy_score(y_val, svm2.predict(X_val))))\n",
    "\n",
    "for c in [0.25]:\n",
    "    svm3 = LinearSVC(C=c)\n",
    "svm3.fit(X_train, y_train)\n",
    "\n",
    "print (\"Accuracy for C=%s: %s\"\n",
    "       % (c, accuracy_score(y_val, svm3.predict(X_val))))\n",
    "\n",
    "for c in [0.5]:\n",
    "    svm4 = LinearSVC(C=c)\n",
    "svm4.fit(X_train, y_train)\n",
    "\n",
    "print (\"Accuracy for C=%s: %s\"\n",
    "       % (c, accuracy_score(y_val, svm4.predict(X_val))))\n",
    "\n",
    "for c in [1]:\n",
    "    svm5 = LinearSVC(C=c)\n",
    "svm5.fit(X_train, y_train)\n",
    "\n",
    "print (\"Accuracy for C=%s: %s\"\n",
    "       % (c, accuracy_score(y_val, svm5.predict(X_val))))\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy for C=0.01: 0.82\n",
    "# Accuracy for C=0.05: 0.84167\n",
    "# Accuracy for C=0.25: 0.8467\n",
    "# Accuracy for C=0.5: 0.8467\n",
    "# Accuracy for C=1: 0.845\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.05, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "final_svm_ngram = LinearSVC(C=0.05)\n",
    "final_svm_ngram.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[257  30]\n",
      " [110 203]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.90      0.79       287\n",
      "           1       0.87      0.65      0.74       313\n",
      "\n",
      "    accuracy                           0.77       600\n",
      "   macro avg       0.79      0.77      0.76       600\n",
      "weighted avg       0.79      0.77      0.76       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_predictions=final_svm_ngram.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_test,test_predictions))\n",
    "print(classification_report(y_test,test_predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
