{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Remi, Ojo]\n",
    "# [5834990]\n",
    "# [MMA]\n",
    "# [2021W]\n",
    "# [MMA869]\n",
    "# [July 11, 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import re\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2202 entries, 0 to 2201\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2202 non-null   object\n",
      " 1   Polarity  2202 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2202 entries, 0 to 2201\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Sentence  2202 non-null   object\n",
      " 1   Polarity  2202 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Polarity\n",
       "0                           Wow... Loved this place.         1\n",
       "1                                 Crust is not good.         0\n",
       "2          Not tasty and the texture was just nasty.         0\n",
       "3  Stopped by during the late May bank holiday of...         1\n",
       "4  The selection on the menu was great and so wer...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product=pd.read_csv(\"C:/Users/8oo/OneDrive/Documents/MMA 865 - Big Data Analytics/Assignment 1/sentiment_train.csv\")\n",
    "product_test=pd.read_csv(\"C:/Users/8oo/OneDrive/Documents/MMA 865 - Big Data Analytics/Assignment 1/sentiment_test.csv\")\n",
    "product.info()\n",
    "\n",
    "product.info()\n",
    "\n",
    "product.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1113\n",
       "1    1089\n",
       "Name: Polarity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the Balance of the dataset specific to polarity\n",
    "product.Polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning // Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(x):\n",
    "    x = x.lower()\n",
    "    \n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    \n",
    "    x = unidecode.unidecode(x)\n",
    "    \n",
    "    x = re.sub(r'\\d+', '', x)\n",
    "    \n",
    "    x = [lemmer.lemmatize(w) for w in x.split() if w not in stop_words]\n",
    "\n",
    "    return ' '.join(x)\n",
    "\n",
    "sentiment_train_clean = product['Sentence'].apply(preprocess)\n",
    "sentiment_test_clean = product_test['Sentence'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      wow loved place\n",
       "1                                           crust good\n",
       "2                                  tasty texture nasty\n",
       "3    stopped late may bank holiday rick steve recom...\n",
       "4                           selection menu great price\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1170)\t1\n",
      "  (0, 1347)\t1\n",
      "  (0, 1846)\t1\n",
      "  (0, 2767)\t1\n",
      "  (0, 3236)\t1\n",
      "  (0, 3586)\t1\n",
      "  (1, 1074)\t1\n",
      "  (1, 1170)\t1\n",
      "  (1, 1186)\t1\n",
      "  (1, 1679)\t1\n",
      "  (1, 1882)\t1\n",
      "  (1, 2266)\t1\n",
      "  (1, 3196)\t1\n",
      "  (2, 552)\t1\n",
      "  (2, 1347)\t1\n",
      "  (2, 1520)\t1\n",
      "  (2, 1747)\t1\n",
      "  (2, 2339)\t1\n",
      "  (2, 2514)\t1\n",
      "  (3, 433)\t1\n",
      "  (3, 552)\t1\n",
      "  (3, 1158)\t1\n",
      "  (3, 1170)\t1\n",
      "  (3, 3181)\t1\n",
      "  (4, 1529)\t1\n",
      "  :\t:\n",
      "  (539, 3032)\t1\n",
      "  (539, 3566)\t1\n",
      "  (540, 1140)\t1\n",
      "  (540, 2018)\t1\n",
      "  (540, 2072)\t1\n",
      "  (540, 3469)\t1\n",
      "  (541, 343)\t1\n",
      "  (541, 1352)\t1\n",
      "  (541, 3133)\t1\n",
      "  (541, 3488)\t1\n",
      "  (542, 1170)\t1\n",
      "  (542, 1836)\t1\n",
      "  (542, 2423)\t1\n",
      "  (542, 2746)\t1\n",
      "  (542, 3348)\t1\n",
      "  (542, 3574)\t1\n",
      "  (543, 1010)\t1\n",
      "  (543, 3572)\t1\n",
      "  (544, 220)\t1\n",
      "  (545, 1524)\t1\n",
      "  (545, 1625)\t1\n",
      "  (545, 1629)\t1\n",
      "  (545, 2000)\t1\n",
      "  (545, 2147)\t1\n",
      "  (545, 3483)\t1\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv = cv.fit(sentiment_train_clean)\n",
    "X = cv.transform(sentiment_train_clean)\n",
    "X_test = cv.transform(sentiment_test_clean)\n",
    "\n",
    "##\n",
    "\n",
    "no_features = 2000\n",
    "\n",
    "tf_vectorizer = CountVectorizer(min_df=0.05, max_df=0.5, max_features=no_features, ngram_range=[1,3])\n",
    "tf_vectorizer = tf_vectorizer.fit_transform(sentiment_train_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Classify some things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classifiers\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "# Import Scoring Metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, roc_auc_score, make_scorer, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1651, 3627)\n",
      "(551, 3627)\n",
      "(551,)\n",
      "(2202, 3627)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Set Random Seed\n",
    "np.random.seed(12)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, product['Polarity'], train_size = 0.75\n",
    ")\n",
    "\n",
    "# Lets check the results\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.6642468239564429\n",
      "F1 C=0.01: 0.5584725536992841\n",
      "Accuracy for C=0.05: 0.7168784029038112\n",
      "F1 C=0.05: 0.6694915254237288\n",
      "Accuracy for C=0.25: 0.7731397459165155\n",
      "F1 C=0.25: 0.7572815533980584\n",
      "Accuracy for C=0.5: 0.7931034482758621\n",
      "F1 C=0.5: 0.7849056603773585\n",
      "Accuracy for C=1: 0.8003629764065335\n",
      "F1 C=1: 0.7962962962962963\n",
      "Accuracy for C=2: 0.8003629764065335\n",
      "F1 C=2: 0.7970479704797048\n"
     ]
    }
   ],
   "source": [
    "for c in [0.01, 0.05, 0.25, 0.5, 1, 2]:\n",
    "    \n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_test, lr.predict(X_test))))\n",
    "    print (\"F1 C=%s: %s\" \n",
    "           % (c, f1_score(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Classifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=12, \n",
    "                             min_samples_split=2, \n",
    "                             min_samples_leaf=30, \n",
    "                             max_depth=6)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.89      0.70       272\n",
      "           1       0.77      0.36      0.49       279\n",
      "\n",
      "    accuracy                           0.62       551\n",
      "   macro avg       0.67      0.63      0.60       551\n",
      "weighted avg       0.67      0.62      0.59       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_dt)\n",
    "\n",
    "#Reporting\n",
    "\n",
    "#Let's look at the total reporting\n",
    "\n",
    "class_names = [str(x) for x in clf.classes_]\n",
    "\n",
    "print(classification_report(y_test, y_pred_dt, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.37\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.94      0.69       272\n",
      "           1       0.81      0.24      0.37       279\n",
      "\n",
      "    accuracy                           0.59       551\n",
      "   macro avg       0.68      0.59      0.53       551\n",
      "weighted avg       0.68      0.59      0.53       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "\n",
    "clf2 = AdaBoostClassifier(n_estimators=200, learning_rate=0.1,random_state=2, algorithm=\"SAMME\")\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "pred_val = clf2.predict(X_test)\n",
    "confusion_matrix(y_test, pred_val)\n",
    "\n",
    "\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, pred_val)))\n",
    "print()\n",
    "print(classification_report(y_test, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.78\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       272\n",
      "           1       0.80      0.76      0.78       279\n",
      "\n",
      "    accuracy                           0.78       551\n",
      "   macro avg       0.78      0.78      0.78       551\n",
      "weighted avg       0.78      0.78      0.78       551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "\n",
    "clf3 = SVC(kernel='linear', random_state=42, gamma=3, degree=7)\n",
    "\n",
    "clf3.fit(X_train, y_train)\n",
    "\n",
    "pred_val = clf3.predict(X_test)\n",
    "confusion_matrix(y_test, pred_val)\n",
    "\n",
    "\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, pred_val)))\n",
    "print()\n",
    "print(classification_report(y_test, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score = 0.80\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80       272\n",
      "           1       0.82      0.77      0.80       279\n",
      "\n",
      "    accuracy                           0.80       551\n",
      "   macro avg       0.80      0.80      0.80       551\n",
      "weighted avg       0.80      0.80      0.80       551\n",
      "\n",
      "\n",
      "[[226  46]\n",
      " [ 64 215]]\n"
     ]
    }
   ],
   "source": [
    "# Taking another look at the Logistic Regression and play around with the solver and the penalty\n",
    "\n",
    "clf4 = LogisticRegression(C=1, solver='liblinear', penalty='l2')\n",
    "clf4.fit(X_train, y_train)\n",
    "pred_val = clf4.predict(X_test)\n",
    "confusion_matrix(y_test, pred_val)\n",
    "\n",
    "print(\"F1 Score = {:.2f}\".format(f1_score(y_test, pred_val)))\n",
    "print()\n",
    "print(classification_report(y_test, pred_val))\n",
    "print()\n",
    "print(confusion_matrix(y_test, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0 has been classified as  0 and should be  1\n",
      "Row 1 has been classified as  0 and should be  1\n",
      "Row 5 has been classified as  0 and should be  1\n",
      "Row 6 has been classified as  0 and should be  1\n",
      "Row 7 has been classified as  1 and should be  0\n",
      "Row 8 has been classified as  0 and should be  1\n",
      "Row 9 has been classified as  0 and should be  1\n",
      "Row 13 has been classified as  0 and should be  1\n",
      "Row 14 has been classified as  0 and should be  1\n",
      "Row 16 has been classified as  1 and should be  0\n",
      "Row 23 has been classified as  1 and should be  0\n",
      "Row 26 has been classified as  1 and should be  0\n",
      "Row 27 has been classified as  1 and should be  0\n",
      "Row 28 has been classified as  1 and should be  0\n",
      "Row 30 has been classified as  1 and should be  0\n",
      "Row 31 has been classified as  1 and should be  0\n",
      "Row 33 has been classified as  1 and should be  0\n",
      "Row 34 has been classified as  1 and should be  0\n",
      "Row 38 has been classified as  0 and should be  1\n",
      "Row 39 has been classified as  1 and should be  0\n",
      "Row 41 has been classified as  1 and should be  0\n",
      "Row 45 has been classified as  1 and should be  0\n",
      "Row 46 has been classified as  0 and should be  1\n",
      "Row 49 has been classified as  0 and should be  1\n",
      "Row 52 has been classified as  1 and should be  0\n",
      "Row 53 has been classified as  1 and should be  0\n",
      "Row 55 has been classified as  1 and should be  0\n",
      "Row 56 has been classified as  1 and should be  0\n",
      "Row 57 has been classified as  1 and should be  0\n",
      "Row 62 has been classified as  1 and should be  0\n",
      "Row 64 has been classified as  1 and should be  0\n",
      "Row 65 has been classified as  1 and should be  0\n",
      "Row 66 has been classified as  1 and should be  0\n",
      "Row 72 has been classified as  1 and should be  0\n",
      "Row 75 has been classified as  1 and should be  0\n",
      "Row 76 has been classified as  1 and should be  0\n",
      "Row 77 has been classified as  1 and should be  0\n",
      "Row 80 has been classified as  1 and should be  0\n",
      "Row 81 has been classified as  1 and should be  0\n",
      "Row 84 has been classified as  0 and should be  1\n",
      "Row 85 has been classified as  0 and should be  1\n",
      "Row 86 has been classified as  0 and should be  1\n",
      "Row 87 has been classified as  0 and should be  1\n",
      "Row 88 has been classified as  1 and should be  0\n",
      "Row 89 has been classified as  1 and should be  0\n",
      "Row 90 has been classified as  0 and should be  1\n",
      "Row 91 has been classified as  0 and should be  1\n",
      "Row 95 has been classified as  0 and should be  1\n",
      "Row 96 has been classified as  0 and should be  1\n",
      "Row 101 has been classified as  0 and should be  1\n",
      "Row 102 has been classified as  0 and should be  1\n",
      "Row 104 has been classified as  0 and should be  1\n",
      "Row 106 has been classified as  1 and should be  0\n",
      "Row 108 has been classified as  1 and should be  0\n",
      "Row 110 has been classified as  1 and should be  0\n",
      "Row 112 has been classified as  0 and should be  1\n",
      "Row 114 has been classified as  1 and should be  0\n",
      "Row 116 has been classified as  1 and should be  0\n",
      "Row 117 has been classified as  1 and should be  0\n",
      "Row 120 has been classified as  1 and should be  0\n",
      "Row 121 has been classified as  1 and should be  0\n",
      "Row 125 has been classified as  1 and should be  0\n",
      "Row 126 has been classified as  1 and should be  0\n",
      "Row 128 has been classified as  1 and should be  0\n",
      "Row 129 has been classified as  1 and should be  0\n",
      "Row 134 has been classified as  1 and should be  0\n",
      "Row 136 has been classified as  1 and should be  0\n",
      "Row 138 has been classified as  1 and should be  0\n",
      "Row 140 has been classified as  0 and should be  1\n",
      "Row 142 has been classified as  0 and should be  1\n",
      "Row 143 has been classified as  0 and should be  1\n",
      "Row 145 has been classified as  0 and should be  1\n",
      "Row 146 has been classified as  1 and should be  0\n",
      "Row 147 has been classified as  1 and should be  0\n",
      "Row 151 has been classified as  1 and should be  0\n",
      "Row 152 has been classified as  1 and should be  0\n",
      "Row 153 has been classified as  1 and should be  0\n",
      "Row 155 has been classified as  1 and should be  0\n",
      "Row 158 has been classified as  1 and should be  0\n",
      "Row 162 has been classified as  1 and should be  0\n",
      "Row 169 has been classified as  0 and should be  1\n",
      "Row 170 has been classified as  0 and should be  1\n",
      "Row 171 has been classified as  1 and should be  0\n",
      "Row 173 has been classified as  1 and should be  0\n",
      "Row 174 has been classified as  1 and should be  0\n",
      "Row 176 has been classified as  1 and should be  0\n",
      "Row 177 has been classified as  0 and should be  1\n",
      "Row 181 has been classified as  1 and should be  0\n",
      "Row 182 has been classified as  1 and should be  0\n",
      "Row 186 has been classified as  1 and should be  0\n",
      "Row 188 has been classified as  1 and should be  0\n",
      "Row 189 has been classified as  1 and should be  0\n",
      "Row 190 has been classified as  1 and should be  0\n",
      "Row 192 has been classified as  0 and should be  1\n",
      "Row 193 has been classified as  0 and should be  1\n",
      "Row 195 has been classified as  0 and should be  1\n",
      "Row 197 has been classified as  0 and should be  1\n",
      "Row 199 has been classified as  1 and should be  0\n",
      "Row 200 has been classified as  0 and should be  1\n",
      "Row 202 has been classified as  1 and should be  0\n",
      "Row 204 has been classified as  1 and should be  0\n",
      "Row 205 has been classified as  1 and should be  0\n",
      "Row 206 has been classified as  1 and should be  0\n",
      "Row 207 has been classified as  1 and should be  0\n",
      "Row 209 has been classified as  1 and should be  0\n",
      "Row 211 has been classified as  0 and should be  1\n",
      "Row 214 has been classified as  1 and should be  0\n",
      "Row 216 has been classified as  1 and should be  0\n",
      "Row 217 has been classified as  0 and should be  1\n",
      "Row 218 has been classified as  0 and should be  1\n",
      "Row 219 has been classified as  0 and should be  1\n",
      "Row 220 has been classified as  0 and should be  1\n",
      "Row 221 has been classified as  0 and should be  1\n",
      "Row 222 has been classified as  0 and should be  1\n",
      "Row 223 has been classified as  0 and should be  1\n",
      "Row 226 has been classified as  1 and should be  0\n",
      "Row 229 has been classified as  0 and should be  1\n",
      "Row 230 has been classified as  0 and should be  1\n",
      "Row 232 has been classified as  0 and should be  1\n",
      "Row 234 has been classified as  1 and should be  0\n",
      "Row 235 has been classified as  0 and should be  1\n",
      "Row 236 has been classified as  0 and should be  1\n",
      "Row 237 has been classified as  0 and should be  1\n",
      "Row 238 has been classified as  0 and should be  1\n",
      "Row 239 has been classified as  0 and should be  1\n",
      "Row 240 has been classified as  0 and should be  1\n",
      "Row 241 has been classified as  0 and should be  1\n",
      "Row 244 has been classified as  0 and should be  1\n",
      "Row 245 has been classified as  1 and should be  0\n",
      "Row 246 has been classified as  1 and should be  0\n",
      "Row 248 has been classified as  0 and should be  1\n",
      "Row 249 has been classified as  0 and should be  1\n",
      "Row 252 has been classified as  0 and should be  1\n",
      "Row 253 has been classified as  0 and should be  1\n",
      "Row 254 has been classified as  0 and should be  1\n",
      "Row 255 has been classified as  0 and should be  1\n",
      "Row 256 has been classified as  0 and should be  1\n",
      "Row 258 has been classified as  0 and should be  1\n",
      "Row 261 has been classified as  0 and should be  1\n",
      "Row 263 has been classified as  0 and should be  1\n",
      "Row 264 has been classified as  1 and should be  0\n",
      "Row 265 has been classified as  1 and should be  0\n",
      "Row 266 has been classified as  0 and should be  1\n",
      "Row 270 has been classified as  0 and should be  1\n",
      "Row 271 has been classified as  0 and should be  1\n",
      "Row 274 has been classified as  0 and should be  1\n",
      "Row 275 has been classified as  0 and should be  1\n",
      "Row 280 has been classified as  0 and should be  1\n",
      "Row 283 has been classified as  0 and should be  1\n",
      "Row 284 has been classified as  0 and should be  1\n",
      "Row 285 has been classified as  1 and should be  0\n",
      "Row 291 has been classified as  0 and should be  1\n",
      "Row 293 has been classified as  0 and should be  1\n",
      "Row 294 has been classified as  0 and should be  1\n",
      "Row 296 has been classified as  1 and should be  0\n",
      "Row 297 has been classified as  1 and should be  0\n",
      "Row 298 has been classified as  1 and should be  0\n",
      "Row 302 has been classified as  1 and should be  0\n",
      "Row 305 has been classified as  1 and should be  0\n",
      "Row 306 has been classified as  1 and should be  0\n",
      "Row 308 has been classified as  1 and should be  0\n",
      "Row 310 has been classified as  1 and should be  0\n",
      "Row 312 has been classified as  0 and should be  1\n",
      "Row 317 has been classified as  1 and should be  0\n",
      "Row 318 has been classified as  1 and should be  0\n",
      "Row 320 has been classified as  1 and should be  0\n",
      "Row 323 has been classified as  1 and should be  0\n",
      "Row 326 has been classified as  1 and should be  0\n",
      "Row 328 has been classified as  0 and should be  1\n",
      "Row 329 has been classified as  0 and should be  1\n",
      "Row 332 has been classified as  0 and should be  1\n",
      "Row 334 has been classified as  0 and should be  1\n",
      "Row 337 has been classified as  1 and should be  0\n",
      "Row 339 has been classified as  1 and should be  0\n",
      "Row 340 has been classified as  0 and should be  1\n",
      "Row 342 has been classified as  0 and should be  1\n",
      "Row 343 has been classified as  0 and should be  1\n",
      "Row 344 has been classified as  0 and should be  1\n",
      "Row 346 has been classified as  0 and should be  1\n",
      "Row 347 has been classified as  0 and should be  1\n",
      "Row 348 has been classified as  0 and should be  1\n",
      "Row 349 has been classified as  0 and should be  1\n",
      "Row 352 has been classified as  0 and should be  1\n",
      "Row 354 has been classified as  0 and should be  1\n",
      "Row 356 has been classified as  0 and should be  1\n",
      "Row 358 has been classified as  0 and should be  1\n",
      "Row 359 has been classified as  1 and should be  0\n",
      "Row 361 has been classified as  0 and should be  1\n",
      "Row 363 has been classified as  0 and should be  1\n",
      "Row 364 has been classified as  0 and should be  1\n",
      "Row 366 has been classified as  1 and should be  0\n",
      "Row 368 has been classified as  0 and should be  1\n",
      "Row 369 has been classified as  0 and should be  1\n",
      "Row 370 has been classified as  0 and should be  1\n",
      "Row 372 has been classified as  0 and should be  1\n",
      "Row 373 has been classified as  0 and should be  1\n",
      "Row 376 has been classified as  1 and should be  0\n",
      "Row 379 has been classified as  1 and should be  0\n",
      "Row 380 has been classified as  1 and should be  0\n",
      "Row 381 has been classified as  1 and should be  0\n",
      "Row 384 has been classified as  0 and should be  1\n",
      "Row 385 has been classified as  0 and should be  1\n",
      "Row 386 has been classified as  0 and should be  1\n",
      "Row 387 has been classified as  0 and should be  1\n",
      "Row 389 has been classified as  0 and should be  1\n",
      "Row 390 has been classified as  0 and should be  1\n",
      "Row 391 has been classified as  0 and should be  1\n",
      "Row 394 has been classified as  0 and should be  1\n",
      "Row 395 has been classified as  0 and should be  1\n",
      "Row 396 has been classified as  0 and should be  1\n",
      "Row 397 has been classified as  0 and should be  1\n",
      "Row 400 has been classified as  1 and should be  0\n",
      "Row 403 has been classified as  1 and should be  0\n",
      "Row 406 has been classified as  1 and should be  0\n",
      "Row 407 has been classified as  0 and should be  1\n",
      "Row 410 has been classified as  0 and should be  1\n",
      "Row 413 has been classified as  0 and should be  1\n",
      "Row 414 has been classified as  0 and should be  1\n",
      "Row 415 has been classified as  0 and should be  1\n",
      "Row 416 has been classified as  0 and should be  1\n",
      "Row 418 has been classified as  0 and should be  1\n",
      "Row 420 has been classified as  0 and should be  1\n",
      "Row 425 has been classified as  0 and should be  1\n",
      "Row 426 has been classified as  0 and should be  1\n",
      "Row 427 has been classified as  0 and should be  1\n",
      "Row 428 has been classified as  0 and should be  1\n",
      "Row 431 has been classified as  0 and should be  1\n",
      "Row 435 has been classified as  1 and should be  0\n",
      "Row 437 has been classified as  1 and should be  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 440 has been classified as  1 and should be  0\n",
      "Row 441 has been classified as  1 and should be  0\n",
      "Row 442 has been classified as  0 and should be  1\n",
      "Row 443 has been classified as  0 and should be  1\n",
      "Row 447 has been classified as  1 and should be  0\n",
      "Row 450 has been classified as  1 and should be  0\n",
      "Row 452 has been classified as  1 and should be  0\n",
      "Row 453 has been classified as  1 and should be  0\n",
      "Row 454 has been classified as  1 and should be  0\n",
      "Row 457 has been classified as  1 and should be  0\n",
      "Row 459 has been classified as  1 and should be  0\n",
      "Row 461 has been classified as  0 and should be  1\n",
      "Row 467 has been classified as  0 and should be  1\n",
      "Row 468 has been classified as  1 and should be  0\n",
      "Row 470 has been classified as  1 and should be  0\n",
      "Row 472 has been classified as  0 and should be  1\n",
      "Row 473 has been classified as  0 and should be  1\n",
      "Row 476 has been classified as  0 and should be  1\n",
      "Row 477 has been classified as  0 and should be  1\n",
      "Row 482 has been classified as  0 and should be  1\n",
      "Row 483 has been classified as  0 and should be  1\n",
      "Row 486 has been classified as  0 and should be  1\n",
      "Row 487 has been classified as  0 and should be  1\n",
      "Row 488 has been classified as  0 and should be  1\n",
      "Row 489 has been classified as  0 and should be  1\n",
      "Row 490 has been classified as  0 and should be  1\n",
      "Row 495 has been classified as  0 and should be  1\n",
      "Row 500 has been classified as  1 and should be  0\n",
      "Row 504 has been classified as  0 and should be  1\n",
      "Row 505 has been classified as  0 and should be  1\n",
      "Row 506 has been classified as  0 and should be  1\n",
      "Row 507 has been classified as  0 and should be  1\n",
      "Row 508 has been classified as  0 and should be  1\n",
      "Row 510 has been classified as  0 and should be  1\n",
      "Row 511 has been classified as  0 and should be  1\n",
      "Row 512 has been classified as  0 and should be  1\n",
      "Row 515 has been classified as  0 and should be  1\n",
      "Row 517 has been classified as  0 and should be  1\n",
      "Row 520 has been classified as  1 and should be  0\n",
      "Row 522 has been classified as  0 and should be  1\n",
      "Row 524 has been classified as  0 and should be  1\n",
      "Row 527 has been classified as  0 and should be  1\n",
      "Row 530 has been classified as  0 and should be  1\n",
      "Row 532 has been classified as  0 and should be  1\n",
      "Row 533 has been classified as  0 and should be  1\n",
      "Row 535 has been classified as  0 and should be  1\n",
      "Row 536 has been classified as  0 and should be  1\n",
      "Row 540 has been classified as  1 and should be  0\n",
      "Row 544 has been classified as  1 and should be  0\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the predictions\n",
    "\n",
    "for row_index, (input, prediction, label) in enumerate(zip (X_test, pred_val, product_test['Polarity'])):\n",
    "  if prediction != label:\n",
    "    print('Row', row_index, 'has been classified as ', prediction, 'and should be ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows 0,5,13,16,23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = product_test.loc[0]\n",
    "b = product_test.loc[5]\n",
    "c = product_test.loc[13]\n",
    "d = product_test.loc[16]\n",
    "e = product_test.loc[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence    A good commentary of today's love and undoubte...\n",
      "Polarity                                                    1\n",
      "Name: 0, dtype: object Sentence    I rather enjoyed it.  \n",
      "Polarity                         1\n",
      "Name: 5, dtype: object Sentence    The camera really likes her in this movie.  \n",
      "Polarity                                               1\n",
      "Name: 13, dtype: object Sentence    I am a fan of his ... This movie sucked really...\n",
      "Polarity                                                    0\n",
      "Name: 16, dtype: object Sentence    Now we were chosen to be tortured with this di...\n",
      "Polarity                                                    0\n",
      "Name: 23, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(a,b,c,d,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.6, subjectivity=0.6000000000000001)\n",
      "Sentiment(polarity=0.5, subjectivity=0.7)\n",
      "Sentiment(polarity=0.2, subjectivity=0.2)\n",
      "Sentiment(polarity=0.2, subjectivity=0.2)\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n"
     ]
    }
   ],
   "source": [
    "#Let's check their polarities\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "full = [a,b,c,d,e]\n",
    "\n",
    "for i in full:\n",
    "    tb = TextBlob(str(i))\n",
    "    print(tb.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
